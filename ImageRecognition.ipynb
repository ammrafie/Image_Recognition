{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ImageRecognition.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "D7uuHlarn6V4"
      },
      "source": [
        "# use python 3.6.6 or version problems may occur\n",
        "\n",
        "# commonly img recognition systems use imgs between 128-512px wide\n",
        "# larger than that gets it slow\n",
        "\n",
        "# Inference Phase (A.K.A Prediction)\n",
        "\n",
        "# solution for translation invariance is convolution layer\n",
        "\n",
        "# Max Pooling: A pooling operation that selects the maximum element from the region of the feature map covered by the filter\n",
        "# The objective is to DOWN-SAMPLE an input representation (image, hidden-layer output matrix, etc.), \n",
        "# reducing its dimensionality and allowing for assumptions to be made about features contained in the sub-regions binned.\n",
        "\n",
        "# dropout prevents NN's habit to just memorizing input data\n",
        "\n",
        "# 1. Convolutional layers adds translational invariance\n",
        "# 2. Max pooling layers downsample the data\n",
        "# 3. Dropout forces the NN to learn in a more robust way\n",
        "# 4. Dense layers maps the output of previous layers to the output layer.\n",
        "\n",
        "# 1-3 makes a convolutional block\n",
        "\n",
        "# Latest Design uses branching pathways, shortcuts between groups of layers & others.\n",
        "\n",
        "# Datasets:   CIFAR-10 [(32*32px, 2colorChannels), (10 classes), (60,000 imgs)]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZax2tgV3lew"
      },
      "source": [
        "# Main Code\n",
        "# Explore dataset\n",
        "\n",
        "from keras.datasets import cifar10\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# List of names for each CIFAR10 class\n",
        "cifar10_class_names = {\n",
        "    0: \"Plane\",\n",
        "    1: \"Car\",\n",
        "    2: \"Bird\",\n",
        "    3: \"Cat\",\n",
        "    4: \"Deer\",\n",
        "    5: \"Dog\",\n",
        "    6: \"Frog\",\n",
        "    7: \"Horse\",\n",
        "    8: \"Boat\",\n",
        "    9: \"Truck\"\n",
        "}\n",
        "\n",
        "# Load the entire data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Loop through each picture in the data set\n",
        "for i in range(5):\n",
        "    # Grab an image from the data set\n",
        "    sample_image = x_train[i]\n",
        "    # Grab the image's expected class id\n",
        "    image_class_number = y_train[i][0]\n",
        "    # Look up the class name from the class id\n",
        "    image_class_name = cifar10_class_names[image_class_number]\n",
        "\n",
        "    # Draw the image as a plot\n",
        "    plt.imshow(sample_image)\n",
        "    # Label the image\n",
        "    plt.title(image_class_name)\n",
        "    # Show the plot on the screen\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fe4FQNf07aZU"
      },
      "source": [
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical # () removed from new version\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path\n",
        "\n",
        "# Load data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize data set to 0-to-1 range\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "# Our labels are single values from 0 to 9.\n",
        "# Instead, we want each label to be an array with on element set to 1 and and the rest set to 0.\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "dbseNiE992C0",
        "outputId": "2b6221cd-e0fc-480c-85e2-1a0f84b6fba8"
      },
      "source": [
        "# when doing classification with more than 1 type of obj,\n",
        "# the output layer will almost always use a softmax activation func\n",
        "# It makes sure all class values add up to 100% or 1.\n",
        "\n",
        "# print model summary\n",
        "# model = model\n",
        "# model.summary()\n",
        "\n",
        "# for sound wave we can use 1d convolutional layer but for img we use 2d\n",
        "\n",
        "# each filter detects 1 patterns, \n",
        "# we use padding if the img has left over px after spliting it with (3,3)\n",
        "# the name same has a historical reason. better to memorize it.\n",
        "# conv2d(numOfDifferentFilters, sizeOfWindowforImgTiles(e.g. (3,3)px), padding=\"same\")\n",
        "\n",
        "# to make our NN more powerful we can add more Conv Layer.\n",
        "# for 2nd conv layer we wont have the img so we dont need to use padding.\n",
        "\n",
        "# we use a flatten layer for transition between conv & dense layer\n",
        "\n",
        "# MaxPooling2d(sizeOfAreaWeWannaPoolTogether(e.g. (22,2)squares))\n",
        "\n",
        "# dropOut(percentageofConnectionsToRandomlyCut) # Usally 25-50% works well"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ALeFHTyi95YL",
        "outputId": "f4106c6d-5ed6-4107-ad5d-ab47025dc363"
      },
      "source": [
        "# in keras compiling means we actually want to create the NN in memory.\n",
        "\n",
        "# the loss func defines how to measure how write/wrong the guesses are.\n",
        "# for loss func we can use: categorical_crossentropy, binary_crossentropy\n",
        "\n",
        "# a good optimization algo to start with is adam\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhnLTDqFO1-G"
      },
      "source": [
        "In the fit() method we need to pass in the batch size - how many img we want to feed in the NN at once during training.\n",
        "\n",
        "Setting low num will take long to finish but if high computer will run out of memory. Typical batch size: 32 to 128 imgs.\n",
        "\n",
        "1 full pass through the entire dataset is called an epoch.\n",
        "Eventualy u'll hit a point where additional training doesn't help anymore.\n",
        "\n",
        "The large dataset is, less training passes u'll do on it. (e.g. 1 million img, u might do only 5 passes)\n",
        "\n",
        "It's important to randomize training data order. It's usually default but set explicitly if future version changes it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7AzdalH6Q9Ox"
      },
      "source": [
        "Save training results to reuse"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIqAcFkFSCOR",
        "outputId": "adc3b689-15c0-4804-9522-b5e0a28b4750"
      },
      "source": [
        "Path(\"/content/dummy.txt\").write_text(\"Hello there!\")\n",
        "\n",
        "#hdf5 binary format is designed for saving & loading large binary files efficiently.\n",
        "\n",
        "# when training, in console the lower the loss number is the better our NN is performing.\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-c2UH6mZM1U",
        "outputId": "593d7d44-709b-4b42-93e9-3780d0660a27"
      },
      "source": [
        "# Warning! - Make Adjustments\n",
        "# Main Code\n",
        "\n",
        "\n",
        "import keras\n",
        "from tensorflow.keras.utils import to_categorical # () removed from new version\n",
        "from keras.datasets import cifar10\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path\n",
        "\n",
        "# Load data set\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "# Normalize data set to 0-to-1 range\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "\n",
        "# Convert class vectors to binary class matrices\n",
        "y_train = to_categorical(y_train, 10)\n",
        "y_test = to_categorical(y_test, 10)\n",
        "\n",
        "# Create a model and add layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(32, (3, 3), padding='same', input_shape=(32, 32, 3), activation=\"relu\"))\n",
        "model.add(Conv2D(32, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n",
        "model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512, activation=\"relu\"))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10, activation=\"softmax\"))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer='adam',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=64,\n",
        "    epochs=3, # was 30 epochs\n",
        "    validation_data=(x_test, y_test),\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"/content/model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"/content/model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "782/782 [==============================] - 231s 293ms/step - loss: 1.8011 - accuracy: 0.3332 - val_loss: 1.2001 - val_accuracy: 0.5690\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 1.1960 - accuracy: 0.5729 - val_loss: 0.9444 - val_accuracy: 0.6707\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 228s 292ms/step - loss: 0.9975 - accuracy: 0.6500 - val_loss: 0.8340 - val_accuracy: 0.7085\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4ik4kHyyrdg",
        "outputId": "759814e7-abf1-4249-9293-8ec18786c5d0"
      },
      "source": [
        "# Main Code\n",
        "# Make Predictions\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# These are the CIFAR10 class labels from the training data (in order from 0 to 9)\n",
        "class_labels = [\n",
        "    \"Plane\",\n",
        "    \"Car\",\n",
        "    \"Bird\",\n",
        "    \"Cat\",\n",
        "    \"Deer\",\n",
        "    \"Dog\",\n",
        "    \"Frog\",\n",
        "    \"Horse\",\n",
        "    \"Boat\",\n",
        "    \"Truck\"\n",
        "]\n",
        "\n",
        "# Load the json file that contains the model's structure\n",
        "f = Path(\"/content/model_structure.json\")\n",
        "model_structure = f.read_text()\n",
        "\n",
        "# Recreate the Keras model object from the json data\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Re-load the model's trained weights\n",
        "model.load_weights(\"/content/model_weights.h5\")\n",
        "\n",
        "# Load an image file to test, resizing it to 32x32 pixels (as required by this model)\n",
        "img = image.load_img(\"/content/frog.png\", target_size=(32, 32))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_to_test = image.img_to_array(img)\n",
        "\n",
        "# Add a fourth dimension to the image (since Keras expects a list of images, not a single image)\n",
        "list_of_images = np.expand_dims(image_to_test, axis=0)\n",
        "\n",
        "# Make a prediction using the model\n",
        "results = model.predict(list_of_images)\n",
        "\n",
        "# Since we are only testing one image, we only need to check the first result\n",
        "single_result = results[0]\n",
        "\n",
        "# We will get a likelihood score for all 10 possible classes. Find out which class had the highest score.\n",
        "most_likely_class_index = int(np.argmax(single_result))\n",
        "class_likelihood = single_result[most_likely_class_index]\n",
        "\n",
        "# Get the name of the most likely class\n",
        "class_label = class_labels[most_likely_class_index]\n",
        "\n",
        "# Print the result\n",
        "print(\"This is image is a {} - Likelihood: {:2f}\".format(class_label, class_likelihood))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is image is a Plane - Likelihood: 0.999982\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47wznG9cCMud"
      },
      "source": [
        "We can use pretrained NN in keras to perform img recognition of any of the 1000 types of obj they're already trained on.\n",
        "\n",
        "\n",
        "Transfer Learning: Adapt existing model to recognize new types of objects instead of starting from scratch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Un88u7uqEBnp",
        "outputId": "aa4a9259-9712-4e39-a878-33dd67d0525d"
      },
      "source": [
        "# Main Code\n",
        "# Using a pretrained model\n",
        "# Warning!\n",
        "# Running this for 1st time keras will download latest model of vgg16\n",
        "# Around 100mb of data will be downloaded.\n",
        "\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "\n",
        "# Load Keras' VGG16 model that was pre-trained against the ImageNet database\n",
        "model = vgg16.VGG16()\n",
        "\n",
        "# Load the image file, resizing it to 224x224 pixels (required by this model)\n",
        "img = image.load_img(\"/content/bay.jpg\", target_size=(224, 224))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "x = image.img_to_array(img)\n",
        "\n",
        "# Add a fourth dimension (since Keras expects a list of images)\n",
        "x = np.expand_dims(x, axis=0)\n",
        "\n",
        "# Normalize the input image's pixel values to the range used when training the neural network\n",
        "x = vgg16.preprocess_input(x)\n",
        "\n",
        "# Run the image through the deep neural network to make a prediction\n",
        "predictions = model.predict(x)\n",
        "\n",
        "# Look up the names of the predicted classes. Index zero is the results for the first image.\n",
        "predicted_classes = vgg16.decode_predictions(predictions, top=9)\n",
        "\n",
        "print(\"Top predictions for this image:\")\n",
        "\n",
        "for imagenet_id, name, likelihood in predicted_classes[0]:\n",
        "    print(\"Prediction: {} - {:2f}\".format(name, likelihood))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Top predictions for this image:\n",
            "Prediction: seashore - 0.395213\n",
            "Prediction: promontory - 0.326128\n",
            "Prediction: lakeside - 0.119613\n",
            "Prediction: breakwater - 0.062801\n",
            "Prediction: sandbar - 0.045267\n",
            "Prediction: cliff - 0.011845\n",
            "Prediction: dock - 0.009196\n",
            "Prediction: boathouse - 0.003278\n",
            "Prediction: valley - 0.003194\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f751qOWLXXj9"
      },
      "source": [
        "Transfer Learning: Using a model trained on one set of data as a starting point for modelling a new set of data.\n",
        "\n",
        "A typical CNN is made up of a series of convolutional layers connected to a dense layer.\n",
        "\n",
        "The training process teaches each of those convolutional layers to be activated when it sees certain patterns in the input image. The patterns it looks for gets more & more complex in the upcoming layers.\n",
        "\n",
        "\n",
        "-----------\n",
        "\n",
        "To reuse pretrained NN with new data, we slice off the last layer. We'll keep all the layers that detect patterns, but remove the part that maps those patterns to specific objects. We'll call THIS pretrained NN a Feature Extractor cuz we're using it to extract training features from images.\n",
        "\n",
        "Next we'll create a new NN to replace the last layer in the original network. Our new NN just have to tell which pattern maps to which objects, which is why it can learn to do it with a small amount of training data.\n",
        "\n",
        "\n",
        "Transfer learning is very useful when u don't have a lot of training data but already have a model that solves a similar problem.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK26FCeVDLhz"
      },
      "source": [
        "In keras terminology the top is the last layer of the NN. We need to also tell what size imgs we're using as training data. The images we're using here are 64*64pixels with 3 color channels.\n",
        "\n",
        "---------------------\n",
        "\n",
        "We're using small img sizes in this example to keep the training time as quick as possible, when building your own img recog systems, u can use larger sized imgs like 224*224px."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jk-3wb54JjdZ",
        "outputId": "9a8ff569-bd0f-4de1-f42d-4031d0a5da6e"
      },
      "source": [
        "# Main Code\n",
        "# Transfer Learning - Feature Extraction\n",
        "\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import joblib\n",
        "from keras.preprocessing import image\n",
        "from keras.applications import vgg16\n",
        "\n",
        "# Path to folders with training data\n",
        "dog_path = Path(\"/content/training_data\") / \"dogs\"\n",
        "not_dog_path = Path(\"/content/training_data\") / \"not_dogs\"\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "# Load all the not-dog images\n",
        "for img in not_dog_path.glob(\"*.png\"):\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(img)\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "\n",
        "    # For each 'not dog' image, the expected value should be 0\n",
        "    labels.append(0)\n",
        "\n",
        "# Load all the dog images\n",
        "for img in dog_path.glob(\"*.png\"):\n",
        "    # Load the image from disk\n",
        "    img = image.load_img(img)\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    image_array = image.img_to_array(img)\n",
        "\n",
        "    # Add the image to the list of images\n",
        "    images.append(image_array)\n",
        "\n",
        "    # For each 'dog' image, the expected value should be 1\n",
        "    labels.append(1)\n",
        "\n",
        "# Create a single numpy array with all the images we loaded\n",
        "x_train = np.array(images)\n",
        "\n",
        "# Also convert the labels to a numpy array\n",
        "y_train = np.array(labels)\n",
        "\n",
        "# Normalize image data to 0-to-1 range\n",
        "x_train = vgg16.preprocess_input(x_train)\n",
        "\n",
        "# Load a pre-trained neural network to use as a feature extractor\n",
        "pretrained_nn = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "\n",
        "# Extract features for each image (all in one pass)\n",
        "features_x = pretrained_nn.predict(x_train)\n",
        "\n",
        "# Save the array of extracted features to a file\n",
        "joblib.dump(features_x, \"/content/x_train.dat\")\n",
        "\n",
        "# Save the matching array of expected values to a file\n",
        "joblib.dump(y_train, \"/content/y_train.dat\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "58900480/58889256 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['/content/y_train.dat']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MkCRQ5BZWqS4",
        "outputId": "d9edb083-f005-45e5-f64f-4d72d7deaed9"
      },
      "source": [
        "# Main Code\n",
        "# Transfer Learning - Training with Extracted Features\n",
        "\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from pathlib import Path\n",
        "import joblib\n",
        "\n",
        "# Load data set\n",
        "x_train = joblib.load(\"/content/x_train.dat\")\n",
        "y_train = joblib.load(\"/content/y_train.dat\")\n",
        "\n",
        "# Create a model and add layers\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Flatten(input_shape=x_train.shape[1:]))\n",
        "model.add(Dense(256, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    loss=\"binary_crossentropy\",\n",
        "    optimizer=\"adam\",\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Train the model\n",
        "model.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    epochs=10,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Save neural network structure\n",
        "model_structure = model.to_json()\n",
        "f = Path(\"/content/model_structure.json\")\n",
        "f.write_text(model_structure)\n",
        "\n",
        "# Save neural network's trained weights\n",
        "model.save_weights(\"/content/model_weights.h5\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "2/2 [==============================] - 8s 10ms/step - loss: 12.1955 - accuracy: 0.4917\n",
            "Epoch 2/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 5.7894 - accuracy: 0.7568\n",
            "Epoch 3/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 1.7556 - accuracy: 0.9666\n",
            "Epoch 4/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5766 - accuracy: 0.9781\n",
            "Epoch 5/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 8.6472e-05 - accuracy: 1.0000\n",
            "Epoch 6/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.2815e-08 - accuracy: 1.0000\n",
            "Epoch 7/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1510 - accuracy: 0.9770\n",
            "Epoch 8/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 7.9673e-12 - accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "2/2 [==============================] - 0s 9ms/step - loss: 0.1940 - accuracy: 0.9562\n",
            "Epoch 10/10\n",
            "2/2 [==============================] - 0s 10ms/step - loss: 5.8710e-06 - accuracy: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "433nkSidX5Vr",
        "outputId": "7506fa93-b38c-4624-a715-65ac0c945a39"
      },
      "source": [
        "# print(x_train.shape)\n",
        "# x_train.shape = (numOfImg, pixels, pixels, channels)\n",
        "# x_train.shape[1:] = (pixels, pixels, channels)\n",
        "# (1,2,3,4)[1:] == (2,3,4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(58, 2, 2, 512)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35rtzssBnzxy",
        "outputId": "8b15e2c6-7e51-46de-ec08-a64fca166dd8"
      },
      "source": [
        "# Main Code\n",
        "# Transfer Learning - Make Predictions\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "from keras.applications import vgg16\n",
        "\n",
        "# Load the json file that contains the model's structure\n",
        "f = Path(\"/content/model_structure.json\")\n",
        "model_structure = f.read_text()\n",
        "\n",
        "# Recreate the Keras model object from the json data\n",
        "model = model_from_json(model_structure)\n",
        "\n",
        "# Re-load the model's trained weights\n",
        "model.load_weights(\"/content/model_weights.h5\")\n",
        "\n",
        "# Load an image file to test, resizing it to 64x64 pixels (as required by this model)\n",
        "img = image.load_img(\"/content/dog.png\", target_size=(64, 64))\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "image_array = image.img_to_array(img)\n",
        "\n",
        "# Add a forth dimension to the image (since Keras expects a bunch of images, not a single image)\n",
        "images = np.expand_dims(image_array, axis=0)\n",
        "\n",
        "# Normalize the data\n",
        "images = vgg16.preprocess_input(images)\n",
        "\n",
        "# Use the pre-trained neural network to extract features from our test image (the same way we did to train the model)\n",
        "feature_extraction_model = vgg16.VGG16(weights='imagenet', include_top=False, input_shape=(64, 64, 3))\n",
        "features = feature_extraction_model.predict(images)\n",
        "\n",
        "# Given the extracted features, make a final prediction using our own model\n",
        "results = model.predict(features)\n",
        "\n",
        "# Since we are only testing one image with possible class, we only need to check the first result's first element\n",
        "single_result = results[0][0]\n",
        "\n",
        "# Print the result\n",
        "print(\"Likelihood that this image contains a dog: {}%\".format(int(single_result * 100)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f60b4878a70> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "Likelihood that this image contains a dog: 100%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}